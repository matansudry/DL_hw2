{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial 3\n",
    "\n",
    "In this tutorial we will learn how to \n",
    "* Use dropout in fully connected networks\n",
    "* Use custom datasets in PyTorch\n",
    "* Implement KL divergence\n",
    "\n",
    "So far, we used datasets stored in PyTorch datasets. What happens if we want to use different data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataset import Dataset\n",
    "\n",
    "class SampleDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return (img, label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at a sample dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SampleDataset(Dataset):\n",
    "    def __init__(self, n_features: int = 1024, n_samples: int = 1000):\n",
    "        self.n_features = n_features\n",
    "        self.n_samples = n_samples\n",
    "\n",
    "        self.entries = self._create_entries()\n",
    "\n",
    "    def _create_entries(self):\n",
    "        entries = []\n",
    "\n",
    "        for i in range(self.n_samples):\n",
    "            entries.append({'x': torch.randn(self.n_features), 'y': 1})\n",
    "        \n",
    "        return entries\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        entry = self.entries[index]\n",
    "\n",
    "        return entry['x'], entry['y']\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.entries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's check that it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_dataset = SampleDataset(n_features=5, n_samples=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_loader = DataLoader(sample_dataset, batch_size=4, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch: tensor([[ 0.5660,  0.5490,  0.5353,  1.3392,  0.7686],\n",
      "        [-1.5922, -0.2144, -0.3497,  0.8319, -0.5960],\n",
      "        [ 2.1391,  0.1901, -0.1482,  1.1923, -0.5077],\n",
      "        [-0.5005,  0.9289, -0.8493, -0.4810,  1.0186]])\n",
      "Label batch tensor([1, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "for x, y in sample_loader:\n",
    "    print(f'Input batch: {x}')\n",
    "    print(f'Label batch {y}')\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout\n",
    "\n",
    "Let's add dropout to the model you saw a week ago"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "\n",
    "from torch import nn\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784\n",
    "num_classes = 10\n",
    "num_epochs = 5\n",
    "batch_size = 100\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST Dataset (Images and Labels)\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=[0.3081,],std=[0.1306,])])\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "\n",
    "# Dataset Loader (Input Pipline)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLayers(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(TwoLayers, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, 100)  \n",
    "        self.linear2 = nn.Linear(100, output_size)\n",
    "        \n",
    "        # The only difference from the previous TA\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.linear1(x)\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        return self.linear2(torch.tanh(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters:  79510\n"
     ]
    }
   ],
   "source": [
    "model = TwoLayers(input_size, num_classes)\n",
    "\n",
    "# Loss and Optimizer\n",
    "# Softmax is internally computed.\n",
    "ce_loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "param= [i.nelement() for i in model.parameters()]\n",
    "\n",
    "print (\"number of parameters: \", sum(param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/5], Step: [1/600], Loss: 2.322\n",
      "Epoch: [1/5], Step: [101/600], Loss: 2.149\n",
      "Epoch: [1/5], Step: [201/600], Loss: 1.915\n",
      "Epoch: [1/5], Step: [301/600], Loss: 1.812\n",
      "Epoch: [1/5], Step: [401/600], Loss: 1.768\n",
      "Epoch: [1/5], Step: [501/600], Loss: 1.562\n",
      "Epoch: [2/5], Step: [1/600], Loss: 1.513\n",
      "Epoch: [2/5], Step: [101/600], Loss: 1.497\n",
      "Epoch: [2/5], Step: [201/600], Loss: 1.41\n",
      "Epoch: [2/5], Step: [301/600], Loss: 1.412\n",
      "Epoch: [2/5], Step: [401/600], Loss: 1.321\n",
      "Epoch: [2/5], Step: [501/600], Loss: 1.235\n",
      "Epoch: [3/5], Step: [1/600], Loss: 1.235\n",
      "Epoch: [3/5], Step: [101/600], Loss: 1.185\n",
      "Epoch: [3/5], Step: [201/600], Loss: 1.171\n",
      "Epoch: [3/5], Step: [301/600], Loss: 1.188\n",
      "Epoch: [3/5], Step: [401/600], Loss: 1.11\n",
      "Epoch: [3/5], Step: [501/600], Loss: 1.146\n",
      "Epoch: [4/5], Step: [1/600], Loss: 1.151\n",
      "Epoch: [4/5], Step: [101/600], Loss: 1.136\n",
      "Epoch: [4/5], Step: [201/600], Loss: 0.9381\n",
      "Epoch: [4/5], Step: [301/600], Loss: 0.9362\n",
      "Epoch: [4/5], Step: [401/600], Loss: 0.956\n",
      "Epoch: [4/5], Step: [501/600], Loss: 0.8377\n",
      "Epoch: [5/5], Step: [1/600], Loss: 0.816\n",
      "Epoch: [5/5], Step: [101/600], Loss: 0.8513\n",
      "Epoch: [5/5], Step: [201/600], Loss: 0.8425\n",
      "Epoch: [5/5], Step: [301/600], Loss: 0.8969\n",
      "Epoch: [5/5], Step: [401/600], Loss: 0.8298\n",
      "Epoch: [5/5], Step: [501/600], Loss: 0.7905\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.view(-1, 28*28)        \n",
    "        # Forward + Backward + Optimize\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = ce_loss(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print ('Epoch: [{}/{}], Step: [{}/{}], Loss: {:.4}'.format(epoch+1, num_epochs,\n",
    "                                                                      i+1, len(train_dataset)//batch_size,\n",
    "                                                                      loss.item()))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the 10000 test images:  0.879\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for images, labels in test_loader:\n",
    "    images = images.view(-1, 28*28)\n",
    "    outputs = model(images)\n",
    "    predicted = torch.argmax(outputs, 1)\n",
    "    \n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "\n",
    "print('Accuracy of the model on the 10000 test images: ', float(correct) / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KL divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = torch.Tensor([0.36, 0.48, 0.16])\n",
    "Q = torch.Tensor([0.333, 0.333, 0.333])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0863)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(P * (P / Q).log()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0863)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "F.kl_div(Q.log(), P, None, None, 'sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
