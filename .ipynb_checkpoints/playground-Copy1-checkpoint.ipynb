{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Here, we create a custom dataset\n",
    "\"\"\"\n",
    "import torch\n",
    "import pickle\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle\n",
    "import utils\n",
    "import tqdm\n",
    "from utils.types import PathT\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import DataLoader\n",
    "from typing import Any, Tuple, Dict, List\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from models.base_model import MyModel\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "import h5py\n",
    "# from __future__ import print_function\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(data.Dataset):\n",
    "    \"\"\"\n",
    "    Custom dataset template. Implement the empty functions.\n",
    "    \"\"\"\n",
    "    def __init__(self, image_path, questions_path, answers_path, train=True, answerable_only=False):#, answerable_only=False):\n",
    "        # Set variables\n",
    "        self.image_features_path = image_path\n",
    "        self.questions_path = questions_path\n",
    "        self.answers_path = answers_path\n",
    "\n",
    "        #load the dataset of I, Q, A including the vocab of Q and A\n",
    "        with open(questions_path, 'r') as fd:\n",
    "            self.questions_json = json.load(fd)\n",
    "\n",
    "        if (train):\n",
    "            dataset_type = \"train\"\n",
    "        else:\n",
    "            dataset_type = \"val\"\n",
    "\n",
    "        self.dataset_type = dataset_type\n",
    "\n",
    "        #load question vocab\n",
    "        with open(\"../data/cache/question_vocab_\"+dataset_type, 'r') as fd:\n",
    "            vocab_json = json.load(fd)\n",
    "\n",
    "\n",
    "\n",
    "        #Vocab\n",
    "        self.vocab = vocab_json\n",
    "        self.token_to_index = self.vocab#['question']\n",
    "\n",
    "        with open(\"../data/cache/trainval_ans2label.pkl\", \"rb\") as f:\n",
    "            unpickler = pickle.Unpickler(f)\n",
    "            # if file is not empty scores will be equal\n",
    "            # to the value unpickled\n",
    "            dict_answers = unpickler.load()\n",
    "            self.number_of_answers_per_question = len(dict_answers)\n",
    "\n",
    "\n",
    "        print(\"files upload was done\")\n",
    "\n",
    "        #load Q\n",
    "        if os.path.isfile(\"../data/questions_\"+dataset_type):\n",
    "            self.questions = torch.load(\"../data/questions_\"+dataset_type)\n",
    "        else:\n",
    "            self.questions = list(self.prepare_questions())\n",
    "            self.questions = [self._encode_question(q, self.token_to_index) for q in self.questions] \n",
    "            torch.save(self.questions, \"../data/questions_\"+dataset_type)\n",
    "\n",
    "        print(\"questions done\")\n",
    "\n",
    "        #change Q to Q dict    \n",
    "        if os.path.isfile(\"../data/questions_dict_\"+dataset_type):\n",
    "            with open(\"../data/questions_dict_\"+dataset_type, 'rb') as handle:\n",
    "                self.questions_dict = pickle.load(handle)\n",
    "        else:\n",
    "            self.questions_dict = self.questions_to_dict()\n",
    "            with open(\"../data/questions_dict_\"+dataset_type, 'wb') as handle:\n",
    "                pickle.dump(self.questions_dict, handle)\n",
    "\n",
    "        print(\"questions dict done\")\n",
    "\n",
    "        #Load question_id_to_image_id\n",
    "        if os.path.isfile(\"../data/question_id_to_image_id_\"+dataset_type):\n",
    "            with open(\"../data/question_id_to_image_id_\"+dataset_type, 'r') as fd:\n",
    "                self.question_id_to_image_id = json.load(fd)\n",
    "        else:\n",
    "            self.question_id_to_image_id = self.question_id_to_image_id()\n",
    "            with open(\"../data/question_id_to_image_id_\"+dataset_type, 'w') as fd:\n",
    "                json.dump(self.question_id_to_image_id, fd)\n",
    "\n",
    "        print(\"question_id_to_image_id done\")\n",
    "\n",
    "\n",
    "        #load A\n",
    "        self.answerable_only = answerable_only\n",
    "        if os.path.isfile(\"../data/answerable_with_labels_only_\"+dataset_type+\"_\"+str(answerable_only)):\n",
    "            with open(\"../data/answerable_with_labels_only_\"+dataset_type+\"_\"+str(answerable_only), 'rb') as handle:\n",
    "                self.answerable = pickle.load(handle)\n",
    "        else:\n",
    "            #preprocess A\n",
    "            self.answerable = self.preprocess_answers(train)\n",
    "            if self.answerable_only:\n",
    "                self.answerable = self._find_answerable()\n",
    "            with open(\"../data/answerable_with_labels_only_\"+dataset_type+\"_\"+str(answerable_only), 'wb') as handle:\n",
    "                pickle.dump(self.answerable, handle)\n",
    "\n",
    "        print(\"answers done\")\n",
    "\n",
    "        #load I\n",
    "    #         if os.path.isfile(\"../data/images_\"+dataset_type):\n",
    "    #             with open(\"../data/images_\"+dataset_type, 'rb') as handle:\n",
    "    #                 self.images = pickle.load(handle)\n",
    "\n",
    "    #         else:\n",
    "    #             #preprocess A\n",
    "    #             self.images = self.load_images()\n",
    "    #             with open(\"../data/images_\"+dataset_type, 'wb') as handle:\n",
    "    #                 pickle.dump(self.images, handle)\n",
    "        if os.path.isfile(\"../data/cache/\"+dataset_type+\".h5\"):\n",
    "            #self.images = h5py.File(\"../data/cache/\"+dataset_type+\".h5\", 'r')\n",
    "            with open(\"../data/cache/img2idx_\"+dataset_type+\".pkl\", 'rb') as handle:\n",
    "                self.img2idx = pickle.load(handle)\n",
    "\n",
    "        else:\n",
    "            #preprocess A\n",
    "    #             self.images = self.load_images()\n",
    "    #             with open(\"../data/images_\"+dataset_type, 'wb') as handle:\n",
    "    #                 pickle.dump(self.images, handle)\n",
    "            print(\"need to implement\")\n",
    "            raise\n",
    "        print(\"images done\")\n",
    "\n",
    "        #load coco_images_to_dict\n",
    "        if os.path.isfile(\"../data/coco_images_to_dict\"+dataset_type):\n",
    "            with open(\"../data/coco_images_to_dict\"+dataset_type, 'rb') as handle:\n",
    "                self.images_dict = pickle.load(handle)\n",
    "\n",
    "        else:\n",
    "            self.coco_images_to_dict()\n",
    "            with open(\"../data/coco_images_to_dict\"+dataset_type, 'wb') as handle:\n",
    "                pickle.dump(self.images_dict, handle)\n",
    "\n",
    "        print(\"coco_images_to_dict done\")\n",
    "        if train==True:\n",
    "            self.delete_q_without_answer()\n",
    "        self.index_to_question_number_dict = self.index_to_question_number_func()\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        item = self.index_to_question_number_dict[item]\n",
    "        q, q_length = self.questions_dict[item]\n",
    "        a = self.answerable[item]\n",
    "        temp = torch.zeros(self.number_of_answers_per_question)\n",
    "        for answer_index in range(len(a[0])):\n",
    "            temp[a[0][answer_index]] = a[1][answer_index]\n",
    "        image_id = self.question_id_to_image_id[str(item)]\n",
    "        images = h5py.File(\"../data/cache/\"+self.dataset_type+\".h5\", 'r')\n",
    "        image_index = self.img2idx[image_id]\n",
    "        v = images['images'][image_index].astype('float32')\n",
    "        v = torch.from_numpy(v)        \n",
    "        return v, temp, q, item, q_length\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"\n",
    "        :return: the length of the dataset (number of sample).\n",
    "        \"\"\"\n",
    "        return len(self.questions_dict)\n",
    "\n",
    "    def get_transform(self, target_size, central_fraction=1.0):\n",
    "        return transforms.Compose([\n",
    "            transforms.Scale(int(target_size / central_fraction)),\n",
    "            transforms.CenterCrop(target_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "\n",
    "    def load_images(self):\n",
    "        transform = self.get_transform(target_size=224, central_fraction=0.875)\n",
    "        dataset = [CocoImages(self.image_features_path, transform=transform)]\n",
    "    #     dataset = Composite(dataset)\n",
    "        return dataset\n",
    "\n",
    "    @property\n",
    "    def max_question_length(self):\n",
    "        if not hasattr(self, '_max_length'):\n",
    "            self._max_length = max(map(len, self.questions))\n",
    "        return self._max_length\n",
    "\n",
    "    def preprocess_answers(self, train=True):\n",
    "        if train:\n",
    "            with open(\"../data/cache/train_target.pkl\", \"rb\") as f:\n",
    "                unpickler = pickle.Unpickler(f)\n",
    "                scores = unpickler.load()\n",
    "        else:\n",
    "            with open(\"../data/cache/val_target.pkl\", \"rb\") as f:\n",
    "                unpickler = pickle.Unpickler(f)\n",
    "                scores = unpickler.load()  \n",
    "\n",
    "        with open(\"../data/cache/trainval_ans2label.pkl\", \"rb\") as f:\n",
    "            unpickler = pickle.Unpickler(f)\n",
    "            # if file is not empty scores will be equal\n",
    "            # to the value unpickled\n",
    "            dict_answers = unpickler.load()\n",
    "            self.number_of_answers_per_question = len(dict_answers)\n",
    "\n",
    "        answers_dict = {}\n",
    "        for item in scores:\n",
    "            answers_dict[item['question_id']] = ((item['labels'], item['scores']))\n",
    "\n",
    "        return answers_dict\n",
    "\n",
    "    def questions_to_dict(self):\n",
    "        question_dict = {}\n",
    "        for i in range(len(self.questions_json['questions'])):\n",
    "            question_dict[self.questions_json['questions'][i]['question_id']] = self.questions[i] \n",
    "        return (question_dict)\n",
    "\n",
    "    def question_id_to_image_id(self):\n",
    "        question_id_dict = {}\n",
    "        for i in range(len(self.questions_json['questions'])):\n",
    "            question_id_dict[str(self.questions_json['questions'][i]['question_id'])] = self.questions_json['questions'][i]['image_id']\n",
    "        return (question_id_dict)\n",
    "\n",
    "    def _find_answerable(self):\n",
    "        update_answers = self.answerable.copy()\n",
    "        for answer in tqdm.tqdm(self.answerable):\n",
    "            if (sum(self.answerable[answer])==0):\n",
    "                del update_answers[answer]\n",
    "        return(update_answers)\n",
    "\n",
    "    def prepare_questions(self):\n",
    "        \"\"\" Tokenize and normalize questions from a given question json in the usual VQA format. \"\"\"\n",
    "        questions = [q['question'] for q in self.questions_json['questions']]\n",
    "        for question in questions:\n",
    "            question = question.lower()[:-1]\n",
    "            yield question.split(' ')\n",
    "\n",
    "    def _encode_question(self, question, token_to_index):\n",
    "        \"\"\" Turn a question into a vector of indices and a question length \"\"\"\n",
    "        vec = torch.zeros(self.max_question_length).long()\n",
    "        for i, token in enumerate(question):\n",
    "            index = token_to_index.get(token, 0)\n",
    "            vec[i] = index\n",
    "        return vec, len(question)\n",
    "\n",
    "    def index_to_question_number_func(self):\n",
    "        index_to_question_number_dict = {}\n",
    "        cnt = 0\n",
    "        for question in self.answerable:\n",
    "            index_to_question_number_dict[cnt] = question\n",
    "            cnt += 1\n",
    "        return index_to_question_number_dict\n",
    "\n",
    "    def coco_images_to_dict(self):\n",
    "        images_dict= {}\n",
    "        images = self.images[0]\n",
    "        cnt = 0\n",
    "        for image in tqdm.tqdm(images):\n",
    "            images_dict[image[0]] = cnt\n",
    "            cnt +=1\n",
    "        self.images_dict = images_dict\n",
    "    def num_tokens(self):\n",
    "        return len(self.vocab) + 1\n",
    "    \n",
    "    def delete_q_without_answer(self):\n",
    "        temp = []\n",
    "        for i in self.answerable:\n",
    "            if len(train_dataset.answerable[i][0])<1:\n",
    "                temp.append(i)\n",
    "        for i in range(len(temp)):\n",
    "            del self.answerable[temp[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_q_without_answer(self):\n",
    "    temp = []\n",
    "    for i in self.answerable:\n",
    "        if len(train_dataset.answerable[i][0])<1:\n",
    "            temp.append(i)\n",
    "    for i in range(len(temp)):\n",
    "        del self.answerable[temp[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files upload was done\n",
      "questions done\n",
      "questions dict done\n",
      "question_id_to_image_id done\n",
      "answers done\n",
      "images done\n",
      "coco_images_to_dict done\n"
     ]
    }
   ],
   "source": [
    "train_dataset = MyDataset(image_path='../../../datashare/train2014',\n",
    "                          questions_path='../../../datashare/v2_OpenEnded_mscoco_train2014_questions.json',\n",
    "                          answers_path='../../../datashare/v2_mscoco_train2014_annotations.json',\n",
    "                          train=True,\n",
    "                          answerable_only = False\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7fc84a801dd0>\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Caught OSError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/matansudry/miniconda3/envs/matan_env/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py\", line 185, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/matansudry/miniconda3/envs/matan_env/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/matansudry/miniconda3/envs/matan_env/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"<ipython-input-33-593b2e652454>\", line 136, in __getitem__\n    images = h5py.File(\"../data/cache/\"+self.dataset_type+\".h5\", 'r')\n  File \"/home/matansudry/miniconda3/envs/matan_env/lib/python3.7/site-packages/h5py/_hl/files.py\", line 427, in __init__\n    swmr=swmr)\n  File \"/home/matansudry/miniconda3/envs/matan_env/lib/python3.7/site-packages/h5py/_hl/files.py\", line 190, in make_fid\n    fid = h5f.open(name, flags, fapl=fapl)\n  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n  File \"h5py/h5f.pyx\", line 96, in h5py.h5f.open\nOSError: Unable to open file (file is already open for write (may use <h5clear file> to clear file consistency flags))\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-fcd66e7e3666>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/matan_env/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/matan_env/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    987\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 989\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    990\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/matan_env/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/matan_env/lib/python3.7/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0;31m# (https://bugs.python.org/issue2651), so we work around it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyErrorMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m: Caught OSError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/matansudry/miniconda3/envs/matan_env/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py\", line 185, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/matansudry/miniconda3/envs/matan_env/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/matansudry/miniconda3/envs/matan_env/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"<ipython-input-33-593b2e652454>\", line 136, in __getitem__\n    images = h5py.File(\"../data/cache/\"+self.dataset_type+\".h5\", 'r')\n  File \"/home/matansudry/miniconda3/envs/matan_env/lib/python3.7/site-packages/h5py/_hl/files.py\", line 427, in __init__\n    swmr=swmr)\n  File \"/home/matansudry/miniconda3/envs/matan_env/lib/python3.7/site-packages/h5py/_hl/files.py\", line 190, in make_fid\n    fid = h5f.open(name, flags, fapl=fapl)\n  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n  File \"h5py/h5f.pyx\", line 96, in h5py.h5f.open\nOSError: Unable to open file (file is already open for write (may use <h5clear file> to clear file consistency flags))\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=6)\n",
    "print(train_loader)\n",
    "for i in train_loader:\n",
    "    print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-8f5f7d61b367>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mques\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_len\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mques\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "import tqdm as tqdm\n",
    "for img, ans, ques, _, q_len in tqdm(train_loader):\n",
    "    print(ques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "for i in train_dataset.answerable:\n",
    "    train_dataset.answerable[i][0]\n",
    "    if len(train_dataset.answerable[i][0])<1:\n",
    "        temp.append(i)\n",
    "#     print(i)\n",
    "#     if i[0] == None:\n",
    "#         print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "443757"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset.answerable)\n",
    "# 443757"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "433112"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset.answerable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "matan_env",
   "language": "python",
   "name": "matan_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
