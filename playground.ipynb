{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import hydra\n",
    "\n",
    "from train import train\n",
    "from dataset import MyDataset\n",
    "from models.base_model import MyModel\n",
    "from torch.utils.data import DataLoader\n",
    "from utils import main_utils, train_utils\n",
    "from utils.train_logger import TrainLogger\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = torch.load('model.pth',map_location=lambda storage, loc: storage)\n",
    "temp1 = temp['model_state']\n",
    "torch.save(temp1, 'model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "matan = torch.load('model.pkl', map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(145614)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matan[\"module.img_encoder.feature_extractor.1.num_batches_tracked\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "old = [\"module.fc1.weight\", \"module.fc1.bias\", \"module.fc2.weight\", \"module.fc2.bias\",\n",
    "       \"module.img_encoder.feature_extractor.0.weight\", \"module.img_encoder.feature_extractor.1.weight\",\n",
    "       \"module.img_encoder.feature_extractor.1.bias\", \"module.img_encoder.feature_extractor.1.running_mean\",\n",
    "       \"module.img_encoder.feature_extractor.1.running_var\",\n",
    "       \"module.img_encoder.feature_extractor.4.main_path.0.weight\", \"module.img_encoder.feature_extractor.4.main_path.0.bias\",\n",
    "       \"module.img_encoder.feature_extractor.4.main_path.1.weight\", \"module.img_encoder.feature_extractor.4.main_path.1.bias\",\n",
    "       \"module.img_encoder.feature_extractor.4.main_path.1.running_mean\", \"module.img_encoder.feature_extractor.4.main_path.1.running_var\",\n",
    "       \"module.img_encoder.feature_extractor.5.main_path.0.weight\",\n",
    "       \"module.img_encoder.feature_extractor.5.main_path.0.bias\", \"module.img_encoder.feature_extractor.5.main_path.1.weight\",\n",
    "       \"module.img_encoder.feature_extractor.5.main_path.1.bias\", \"module.img_encoder.feature_extractor.5.main_path.1.running_mean\",\n",
    "       \"module.img_encoder.feature_extractor.5.main_path.1.running_var\",\n",
    "       \"module.img_encoder.feature_extractor.6.main_path.0.weight\", \"module.img_encoder.feature_extractor.6.main_path.0.bias\",\n",
    "       \"module.img_encoder.feature_extractor.6.main_path.1.weight\", \"module.img_encoder.feature_extractor.6.main_path.1.bias\",\n",
    "       \"module.img_encoder.feature_extractor.6.main_path.1.running_mean\", \"module.img_encoder.feature_extractor.6.main_path.1.running_var\", \"module.img_encoder.feature_extractor.7.main_path.0.weight\",\n",
    "       \"module.img_encoder.feature_extractor.7.main_path.0.bias\", \"module.img_encoder.feature_extractor.7.main_path.1.weight\", \n",
    "       \"module.img_encoder.feature_extractor.7.main_path.1.bias\", \"module.img_encoder.feature_extractor.7.main_path.1.running_mean\",\n",
    "       \"module.img_encoder.feature_extractor.7.main_path.1.running_var\",\n",
    "       \"module.img_encoder.feature_extractor.8.main_path.0.weight\", \"module.img_encoder.feature_extractor.8.main_path.0.bias\", \n",
    "       \"module.img_encoder.feature_extractor.8.main_path.1.weight\", \"module.img_encoder.feature_extractor.8.main_path.1.bias\", \n",
    "       \"module.img_encoder.feature_extractor.8.main_path.1.running_mean\", \"module.img_encoder.feature_extractor.8.main_path.1.running_var\", \"module.img_encoder.feature_extractor.9.main_path.0.weight\",\n",
    "       \"module.img_encoder.feature_extractor.9.main_path.0.bias\", \"module.img_encoder.feature_extractor.9.main_path.1.weight\",\n",
    "       \"module.img_encoder.feature_extractor.9.main_path.1.bias\", \"module.img_encoder.feature_extractor.9.main_path.1.running_mean\",\n",
    "       \"module.img_encoder.feature_extractor.9.main_path.1.running_var\",\n",
    "       \"module.img_encoder.feature_extractor.10.main_path.0.weight\", \"module.img_encoder.feature_extractor.10.main_path.0.bias\",\n",
    "       \"module.img_encoder.feature_extractor.10.main_path.1.weight\", \"module.img_encoder.feature_extractor.10.main_path.1.bias\",\n",
    "       \"module.img_encoder.feature_extractor.10.main_path.1.running_mean\", \"module.img_encoder.feature_extractor.10.main_path.1.running_var\", \"module.img_encoder.fc1.weight\", \"module.img_encoder.fc1.bias\",\n",
    "       \"module.img_encoder.fc2.weight\", \"module.img_encoder.fc2.bias\", \"module.text.embedding.weight\", \"module.text.lstm.weight_ih_l0\",\n",
    "       \"module.text.lstm.weight_hh_l0\", \"module.text.lstm.bias_ih_l0\", \"module.text.lstm.bias_hh_l0\", \"module.text.lstm.weight_ih_l1\",\n",
    "       \"module.text.lstm.weight_hh_l1\", \"module.text.lstm.bias_ih_l1\", \"module.text.lstm.bias_hh_l1\", \"module.text.fc.weight\", \"module.text.fc.bias\"]\n",
    "\n",
    "new = [\"fc1.weight\", \"fc1.bias\", \"fc2.weight\", \"fc2.bias\", \"img_encoder.feature_extractor.0.weight\", \"img_encoder.feature_extractor.1.weight\",\n",
    "       \"img_encoder.feature_extractor.1.bias\", \"img_encoder.feature_extractor.1.running_mean\", \"img_encoder.feature_extractor.1.running_var\", \n",
    "       \"img_encoder.feature_extractor.4.main_path.0.weight\", \"img_encoder.feature_extractor.4.main_path.0.bias\",\n",
    "       \"img_encoder.feature_extractor.4.main_path.1.weight\", \"img_encoder.feature_extractor.4.main_path.1.bias\",\n",
    "       \"img_encoder.feature_extractor.4.main_path.1.running_mean\", \"img_encoder.feature_extractor.4.main_path.1.running_var\",\n",
    "       \"img_encoder.feature_extractor.5.main_path.0.weight\", \"img_encoder.feature_extractor.5.main_path.0.bias\",\n",
    "       \"img_encoder.feature_extractor.5.main_path.1.weight\", \"img_encoder.feature_extractor.5.main_path.1.bias\",\n",
    "       \"img_encoder.feature_extractor.5.main_path.1.running_mean\", \"img_encoder.feature_extractor.5.main_path.1.running_var\",\n",
    "       \"img_encoder.feature_extractor.6.main_path.0.weight\", \"img_encoder.feature_extractor.6.main_path.0.bias\", \n",
    "       \"img_encoder.feature_extractor.6.main_path.1.weight\", \"img_encoder.feature_extractor.6.main_path.1.bias\",\n",
    "       \"img_encoder.feature_extractor.6.main_path.1.running_mean\", \"img_encoder.feature_extractor.6.main_path.1.running_var\",\n",
    "       \"img_encoder.feature_extractor.7.main_path.0.weight\", \"img_encoder.feature_extractor.7.main_path.0.bias\", \n",
    "       \"img_encoder.feature_extractor.7.main_path.1.weight\", \"img_encoder.feature_extractor.7.main_path.1.bias\", \n",
    "       \"img_encoder.feature_extractor.7.main_path.1.running_mean\", \"img_encoder.feature_extractor.7.main_path.1.running_var\", \n",
    "       \"img_encoder.feature_extractor.8.main_path.0.weight\", \"img_encoder.feature_extractor.8.main_path.0.bias\", \n",
    "       \"img_encoder.feature_extractor.8.main_path.1.weight\", \"img_encoder.feature_extractor.8.main_path.1.bias\", \n",
    "       \"img_encoder.feature_extractor.8.main_path.1.running_mean\", \"img_encoder.feature_extractor.8.main_path.1.running_var\",\n",
    "       \"img_encoder.feature_extractor.9.main_path.0.weight\", \"img_encoder.feature_extractor.9.main_path.0.bias\", \n",
    "       \"img_encoder.feature_extractor.9.main_path.1.weight\", \"img_encoder.feature_extractor.9.main_path.1.bias\",\n",
    "       \"img_encoder.feature_extractor.9.main_path.1.running_mean\", \"img_encoder.feature_extractor.9.main_path.1.running_var\",\n",
    "       \"img_encoder.feature_extractor.10.main_path.0.weight\", \"img_encoder.feature_extractor.10.main_path.0.bias\", \n",
    "       \"img_encoder.feature_extractor.10.main_path.1.weight\", \"img_encoder.feature_extractor.10.main_path.1.bias\", \n",
    "       \"img_encoder.feature_extractor.10.main_path.1.running_mean\", \"img_encoder.feature_extractor.10.main_path.1.running_var\", \n",
    "       \"img_encoder.fc1.weight\", \"img_encoder.fc1.bias\", \"img_encoder.fc2.weight\", \"img_encoder.fc2.bias\", \"text.embedding.weight\", \n",
    "       \"text.lstm.weight_ih_l0\", \"text.lstm.weight_hh_l0\", \"text.lstm.bias_ih_l0\", \"text.lstm.bias_hh_l0\", \"text.lstm.weight_ih_l1\", \n",
    "       \"text.lstm.weight_hh_l1\", \"text.lstm.bias_ih_l1\", \"text.lstm.bias_hh_l1\", \"text.fc.weight\", \"text.fc.bias\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66\n",
      "66\n"
     ]
    }
   ],
   "source": [
    "print (len(old))\n",
    "print (len(new))\n",
    "\n",
    "new_dict = {}\n",
    "for i in range(len(old)):\n",
    "    new_dict[new[i]] = matan[old[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(new_dict, 'model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@hydra.main(config_path=\"config\", config_name='config')\n",
    "def evaluate_hw2(cfg: DictConfig):\n",
    "    main_utils.init(cfg)\n",
    "    logger = TrainLogger(exp_name_prefix=cfg['main']['experiment_name_prefix'], logs_dir=cfg['main']['paths']['logs'])\n",
    "    print(logger)\n",
    "    logger.write(OmegaConf.to_yaml(cfg))\n",
    "\n",
    "    # Set seed for results reproduction\n",
    "    main_utils.set_seed(cfg['main']['seed'])\n",
    "    \n",
    " \n",
    "    # Load dataset\n",
    "    val_dataset = MyDataset(image_path=cfg['main']['paths']['val_images'],\n",
    "                              questions_path=cfg['main']['paths']['val_qeustions'],\n",
    "                              answers_path=cfg['main']['paths']['val_answers'],\n",
    "                              train=False,\n",
    "                              answerable_only = False\n",
    "                             )\n",
    "                            \n",
    "    dataloader = DataLoader(val_dataset, cfg['train']['batch_size'], shuffle=False,\n",
    "                             num_workers=cfg['main']['num_workers'])\n",
    "\n",
    "    # Init model\n",
    "    image_in_size_input = ((3,224,224))\n",
    "    img_encoder_channels_input = [64, 64, 128, 128, 256, 256, 512]\n",
    "\n",
    "    model = MyModel(image_in_size=image_in_size_input,\n",
    "        img_encoder_out_classes=cfg['train']['img_encoder_out_classes'],\n",
    "        img_encoder_channels=img_encoder_channels_input,\n",
    "        img_encoder_batchnorm=cfg['train']['img_encoder_batchnorm'],\n",
    "        img_encoder_dropout=cfg['train']['img_encoder_dropout'],\n",
    "        text_embedding_tokens=cfg['train']['text_embedding_tokens'],\n",
    "        text_embedding_features=cfg['train']['text_embedding_features'],\n",
    "        text_lstm_features=cfg['train']['text_lstm_features'],\n",
    "        text_dropout=cfg['train']['text_dropout'],\n",
    "        classifier_dropout=cfg['train']['classifier_dropout'],\n",
    "        classifier_mid_features=cfg['train']['classifier_mid_features'],\n",
    "        classifier_out_classes=val_dataset.number_of_answers_per_question\n",
    "        )\n",
    "    \n",
    "    model.load_state_dict(torch.load('model.pth',map_location=lambda storage, loc: storage))\n",
    "\n",
    "    if cfg['main']['parallel']:\n",
    "        model = torch.nn.DataParallel(model)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        model = model.cuda()\n",
    "\n",
    "    logger.write(main_utils.get_model_string(model))\n",
    "\n",
    "    # Run model\n",
    "    train_params = train_utils.get_train_params(cfg)\n",
    "\n",
    "    # Report metrics and hyper parameters to tensorboard\n",
    "    score = 0\n",
    "    loss = 0\n",
    "\n",
    "    loss_func = nn.LogSoftmax(dim=1).to(\"cuda\")\n",
    "\n",
    "    for i, x in enumerate(tqdm(dataloader)):\n",
    "        img = x[0]\n",
    "        ans = x[1]\n",
    "        ques = x[2]\n",
    "        if torch.cuda.is_available():\n",
    "            img = img.cuda()\n",
    "            ans = ans.cuda()\n",
    "            ques = ques.cuda()\n",
    "\n",
    "        y_hat = model((img, ques))\n",
    "        img = None\n",
    "        ques = None\n",
    "        nll = -loss_func(y_hat)\n",
    "        score += train_utils.batch_accuracy(y_hat, ans.data).sum()\n",
    "        ans = answer_norm(ans)\n",
    "        loss += (nll * ans).sum(dim=1).mean()\n",
    "\n",
    "\n",
    "    loss /= len(dataloader.dataset)\n",
    "    score /= len(dataloader.dataset)\n",
    "    score *= 100\n",
    "\n",
    "    return score\n",
    "\n",
    "def answer_norm(ans):\n",
    "    zeros = torch.zeros(ans.shape[1])\n",
    "    zeros = zeros .cuda()\n",
    "    max_values, predicted_index = ans.max(dim=1, keepdim=True)\n",
    "    for i in range(ans.shape[0]):\n",
    "        ans[i] = torch.where(ans[i]==max_values[i], ans[i], zeros)\n",
    "    ans_sum = ans.sum(dim=1)\n",
    "    for i in range(len(ans_sum)):\n",
    "        if ans_sum[i] == 0:\n",
    "            ans_sum[i]=1\n",
    "        ans[i] = ans[i]/ans_sum[i]\n",
    "    return ans\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(evaluate_hw2())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "matan_env",
   "language": "python",
   "name": "matan_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
