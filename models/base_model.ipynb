{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Example for a simple model\n",
    "\"\"\"\n",
    "\n",
    "from abc import ABCMeta\n",
    "# from nets.fc import FCNet\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "import itertools as it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# channels=[32, 64, 64, 64, 64, 64, 64, 128, 128, 128, 128, 128, 128, 256, 256, 256, 256, 256, 256, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-22-5d78e084f71c>, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-22-5d78e084f71c>\"\u001b[0;36m, line \u001b[0;32m8\u001b[0m\n\u001b[0;31m    self.img_encoder = ResNetClassifier(\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class MyModel(nn.Module, metaclass=ABCMeta):\n",
    "    \"\"\"\n",
    "    Example for a simple model\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim: int = 50, num_hid: int = 256, output_dim: int = 2, dropout: float = 0.2):\n",
    "        super(MyModel, self).__init__()\n",
    "        test_params = [\n",
    "        self.img_encoder = ResNetClassifier(\n",
    "            in_size=(3,224,224),\n",
    "            out_classes=1024,\n",
    "            channels=[32, 64, 64, 64, 64, 128, 128, 128, 128, 256, 256, 256, 256, 512, 512, 512, 512, 1024, 1024, 1024, 1024],\n",
    "            pool_every=2,\n",
    "            activation_type='relu',\n",
    "            activation_params=dict(),\n",
    "            pooling_type='avg',\n",
    "            pooling_params=dict(kernel_size=2),\n",
    "            batchnorm=True,\n",
    "            dropout=0.1,\n",
    "        )\n",
    "#         self.img_encoder = ConvClassifier(**test_params)\n",
    "\n",
    "    def forward(self, x) -> Tensor:\n",
    "        img = x[0]\n",
    "        out = self.img_encoder(img)\n",
    "        print(img)\n",
    "        raise\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTIVATIONS = {\"relu\": nn.ReLU, \"lrelu\": nn.LeakyReLU}\n",
    "POOLINGS = {\"avg\": nn.AvgPool2d, \"max\": nn.MaxPool2d}\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        channels: list,\n",
    "        kernel_sizes: list,\n",
    "        batchnorm=False,\n",
    "        dropout=0.0,\n",
    "        activation_type: str = \"relu\",\n",
    "        activation_params: dict = {},\n",
    "        **kwargs,\n",
    "    ):\n",
    "\n",
    "        super().__init__()\n",
    "        assert channels and kernel_sizes\n",
    "        assert len(channels) == len(kernel_sizes)\n",
    "        assert all(map(lambda x: x % 2 == 1, kernel_sizes))\n",
    "\n",
    "        if activation_type not in ACTIVATIONS:\n",
    "            raise ValueError(\"Unsupported activation type\")\n",
    "\n",
    "        self.main_path, self.shortcut_path = None, None\n",
    "        main_layers = []\n",
    "        shortcut_layers = []\n",
    "\n",
    "        # - extract number of conv layers\n",
    "        N = len(channels)\n",
    "\n",
    "        # - first conv layer \n",
    "        main_layers.append(\n",
    "            nn.Conv2d(\n",
    "                in_channels,\n",
    "                channels[0],\n",
    "                kernel_size= kernel_sizes[0],\n",
    "                padding=(int((kernel_sizes[0]-1)/2),\n",
    "                int((kernel_sizes[0]-1)/2)), bias=True))\n",
    "        if dropout !=0:\n",
    "            main_layers.append(torch.nn.Dropout2d(p=dropout))\n",
    "        if batchnorm == True:\n",
    "            main_layers.append(torch.nn.BatchNorm2d(channels[0]))\n",
    "        main_layers.append(ACTIVATIONS[activation_type]())\n",
    "\n",
    "        #middle layers\n",
    "        for i in range(1,N-1):\n",
    "            main_layers.append(\n",
    "                nn.Conv2d(\n",
    "                    channels[i-1],\n",
    "                    channels[i],\n",
    "                    kernel_size= kernel_sizes[i],\n",
    "                    padding=(int((kernel_sizes[i]-1)/2),\n",
    "                    int((kernel_sizes[i]-1)/2)), bias=True))\n",
    "            if dropout !=0:\n",
    "                main_layers.append(torch.nn.Dropout2d(p=dropout))\n",
    "            if batchnorm == True:\n",
    "                main_layers.append(torch.nn.BatchNorm2d(channels[i]))\n",
    "            main_layers.append(ACTIVATIONS[activation_type]())\n",
    "        if N > 1:\n",
    "            main_layers.append(\n",
    "                nn.Conv2d(\n",
    "                    channels[N-2],\n",
    "                    channels[N-1],\n",
    "                    kernel_size= kernel_sizes[N-1],\n",
    "                    padding=(int((kernel_sizes[N-1]-1)/2),\n",
    "                    int((kernel_sizes[N-1]-1)/2)), bias=True))\n",
    "        if (in_channels != channels[N-1]):\n",
    "            shortcut_layers.append(nn.Conv2d (in_channels, channels[N-1], kernel_size= 1, bias=False))\n",
    "\n",
    "        self.main_path = nn.Sequential(*main_layers)\n",
    "        self.shortcut_path = nn.Sequential(*shortcut_layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.main_path(x)\n",
    "        out = out + self.shortcut_path(x)\n",
    "        relu = torch.nn.ReLU()\n",
    "        out = relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNetClassifier(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_size,\n",
    "        out_classes,\n",
    "        channels,\n",
    "        pool_every,\n",
    "#         hidden_dims,\n",
    "        activation_type: str = \"relu\",\n",
    "        activation_params: dict = {},\n",
    "        pooling_type: str = \"max\",\n",
    "        pooling_params: dict = {},\n",
    "        batchnorm=False,\n",
    "        dropout=0.0,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        See arguments of ConvClassifier & ResidualBlock.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "#             in_size, out_classes, channels, pool_every, activation_type,\n",
    "#             activation_params, pooling_type, pooling_params, batchnorm, dropout, **kwargs\n",
    "#         )\n",
    "        self.batchnorm = batchnorm\n",
    "        self.dropout = dropout\n",
    "        self.conv_params=dict(kernel_size=3, stride=1, padding=1)\n",
    "        self.out_classes = out_classes\n",
    "        self.in_size = in_size\n",
    "        self.channels = channels\n",
    "        self.pool_every = pool_every\n",
    "#         self.hidden_dims = hidden_dims\n",
    "        self.activation_type = activation_type\n",
    "        self.activation_params = activation_params\n",
    "        self.pooling_type = pooling_type\n",
    "        self.pooling_params = pooling_params\n",
    "        self.feature_extractor = self._make_feature_extractor()\n",
    "        self.liner = torch.nn.Linear(100, self.out_classes)\n",
    "\n",
    "#         super().__init__(\n",
    "#             in_size, out_classes, channels, pool_every, hidden_dims, **kwargs\n",
    "#         )\n",
    "\n",
    "    def _make_feature_extractor(self):\n",
    "        in_channels, in_h, in_w, = tuple(self.in_size)\n",
    "        layers = []\n",
    "        \n",
    "        # - extract number of conv layers\n",
    "        N = len(self.channels)\n",
    "        \n",
    "        #1st layer\n",
    "        temp_in_channels = in_channels\n",
    "        temp_channels = []\n",
    "        temp_kernel_sizes = []\n",
    "        \n",
    "        #middle layers\n",
    "        for i in range(1,N):\n",
    "            temp_channels.append(self.channels[i-1])\n",
    "            temp_kernel_sizes.append(3)\n",
    "            if ((i % self.pool_every)==0 and i!=0):\n",
    "                layers.append(\n",
    "                    ResidualBlock(\n",
    "                        in_channels=temp_in_channels,\n",
    "                        channels=temp_channels,\n",
    "                        kernel_sizes=temp_kernel_sizes,\n",
    "                        batchnorm=self.batchnorm,\n",
    "                        dropout=self.dropout,\n",
    "                        activation_type=self.activation_type))\n",
    "                temp_in_channels = self.channels[i-1]\n",
    "                temp_channels = []\n",
    "                temp_kernel_sizes = []\n",
    "                layers.append(POOLINGS[self.pooling_type](self.pooling_params['kernel_size']))\n",
    "        temp_channels.append(self.channels[N-1])\n",
    "        temp_kernel_sizes.append(3)\n",
    "        layers.append(ResidualBlock(\n",
    "                in_channels=temp_in_channels,\n",
    "                channels=temp_channels,\n",
    "                kernel_sizes=temp_kernel_sizes,\n",
    "                batchnorm=self.batchnorm,\n",
    "                dropout=self.dropout,\n",
    "                activation_type=self.activation_type))\n",
    "        if ((N % self.pool_every)==0):\n",
    "            layers.append(POOLINGS[self.pooling_type](self.pooling_params['kernel_size']))\n",
    "        seq = nn.Sequential(*layers)\n",
    "        return seq\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        features = self.feature_extractor(x)\n",
    "        features = features.view(features.size(0), -1)\n",
    "        features = self.liner(features)\n",
    "        return features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "matan_env",
   "language": "python",
   "name": "matan_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
